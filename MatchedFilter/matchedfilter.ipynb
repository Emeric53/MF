{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匹配滤波算法及其变体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要的库和依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"C:\\\\Users\\\\RS\\\\VSCode\\\\matchedfiltermethod\")\n",
    "import MyFunctions.AHSI_data as ad\n",
    "import MyFunctions.EMIT_data as ed\n",
    "from MyFunctions.needed_function import open_unit_absorption_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整幅影像进行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常规匹配滤波算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# original matched filter algorithm 整幅图像进行计算\n",
    "def matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array, albedoadjust, iterate, sparsity):        \n",
    "    \"\"\"\n",
    "    Calculate the methane enhancement of the image data based on the original matched filter\n",
    "    and the unit absorption spectrum.\n",
    "    \n",
    "    :param data_array: numpy array of the image data\n",
    "    :param unit_absorption_spectrum: list of the unit absorption spectrum\n",
    "    \"\"\"\n",
    "    # 获取波段 行数 列数 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    \n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    background_spectrum = np.nanmean(data_cube, axis=(1,2))\n",
    "    target_spectrum = background_spectrum*unit_absorption_spectrum\n",
    "    radiancediff_with_bg =data_cube - background_spectrum[:, None,None]\n",
    "    \n",
    "    # 计算协方差矩阵，并获得其逆矩阵\n",
    "    d_covariance = radiancediff_with_bg\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "    \n",
    "    # 判断是否进行反照率校正，若是，则通过背景光谱和实际光谱计算反照率校正因子\n",
    "    albedo = np.ones((rows, cols))\n",
    "    if albedoadjust:\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                albedo[row, col] = (\n",
    "                        (data_cube[:,row,col].T @ background_spectrum) /\n",
    "                        (background_spectrum.T @ background_spectrum)\n",
    "                )\n",
    "    \n",
    "    # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum)\n",
    "            denominator = albedo[row,col]*(target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "    \n",
    "    # for row in range(rows):\n",
    "    #     for col in range(cols):\n",
    "    #         numerator = (radiancediff_with_bg[:,row,col].T @ target_spectrum)\n",
    "    #         denominator = albedo[row,col]*(target_spectrum.T @ target_spectrum)\n",
    "    #         concentration[row,col] = numerator/denominator\n",
    "    \n",
    "    # 判断是否进行迭代，若是，则进行如下迭代计算\n",
    "    if iterate:\n",
    "        # 初始化 l1filter 数组\n",
    "        l1filter = np.zeros((rows,cols))\n",
    "        for iter_num in range(5):\n",
    "            print(\"iteration: No.\", iter_num + 1)\n",
    "            # 判断是否进行 l1filter 校正，若是则给予前一步的浓度值计算 l1filter\n",
    "            if sparsity:\n",
    "                for row in rows:\n",
    "                    for col in cols:\n",
    "                        l1filter = 1 / (concentration[row,col] + np.finfo(np.float64).tiny)\n",
    "            \n",
    "            # 更新背景光谱和目标光谱,并计算进行观测光谱和背景光谱差值   \n",
    "            updated_array = data_cube - (albedo*concentration)[None,:,:]*target_spectrum[:,None,None]\n",
    "            background_spectrum = np.mean(updated_array, axis=(1,2))\n",
    "            target_spectrum = np.multiply(background_spectrum, unit_absorption_spectrum)\n",
    "            radiancediff_with_bg = data_cube - background_spectrum[:,None,None]\n",
    "            \n",
    "            # 基于新的目标谱和背景光谱 计算协方差矩阵\n",
    "            d_covariance = data_cube -(albedo*concentration)[None,:,:]*target_spectrum[:,None,None] - background_spectrum[:,None,None]\n",
    "            covariance = np.zeros((bands, bands))\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    covariance += np.outer(d_covariance[:,row,col], d_covariance[:,row,col])\n",
    "            covariance = covariance/(rows*cols)\n",
    "            covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "            # 基于最优化估计公式 计算新的甲烷浓度增强值\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum) - l1filter[row,col]\n",
    "                    denominator = albedo[row,col] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                    concentration[row,col] = np.maximum(numerator / denominator, 0.0)\n",
    "                  \n",
    "            # for row in range(rows):\n",
    "            #     for col in range(cols):\n",
    "            #         numerator = (radiancediff_with_bg[:,row,col].T @ target_spectrum) - l1filter[row,col]\n",
    "            #         denominator = albedo[row,col] * (target_spectrum.T @ target_spectrum)\n",
    "            #         concentration[row,col] = np.maximum(numerator / denominator, 0.0)\n",
    "    return concentration\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层匹配滤波算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# modified matched filter algorithm 整幅图像进行计算\n",
    "def modified_matched_filter_copy(data_cube: np.array, unit_absorption_spectrum: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Calculate the methane enhancement of the image data based on the original matched filter\n",
    "    and the unit absorption spectrum.\n",
    "\n",
    "    :param data_cube: numpy array of the image data\n",
    "    :param unit_absorption_spectrum: list of the unit absorption spectrum\n",
    "    :param is_iterate: flag to decide whether to iterate the matched filter\n",
    "    :param is_albedo: flag to decide whether to do the albedo correction\n",
    "    :param is_filter: flag to decide whether to add the l1-filter correction\n",
    "    :return: numpy array of methane enhancement result\n",
    "    \"\"\"\n",
    "    # 获取 以 波段 行数 列数 为顺序的数据\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    # 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    background_spectrum = np.nanmean(data_cube, axis=(1,2))\n",
    "    target_spectrum = background_spectrum*unit_absorption_spectrum[0]\n",
    "    radiancediff_with_bg = data_cube - background_spectrum[:, None,None]\n",
    "\n",
    "    d_covariance = data_cube - background_spectrum[:, None,None]\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum)\n",
    "            denominator = (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "\n",
    "    original_concentration = concentration.copy()\n",
    "    levelon = True\n",
    "    while levelon:\n",
    "        adaptive_threshold = 4000\n",
    "        i = 1\n",
    "        # _, new_unit_absorption_spectrum = lookup_uas_interpolated(adaptive_threshold)\n",
    "        new_unit_absorption_spectrum = unit_absorption_spectrum[i]\n",
    "        high_concentration_mask = concentration > adaptive_threshold\n",
    "        low_concentration_mask = concentration <= adaptive_threshold\n",
    "        if np.sum(high_concentration_mask) > 0:\n",
    "            # 注意：target_spectrum 的更新应该基于更准确的估计值\n",
    "            background_spectrum = np.nanmean(data_cube - concentration * target_spectrum[:, None, None], axis=(1, 2))\n",
    "            target_spectrum = background_spectrum * unit_absorption_spectrum\n",
    "            new_background_spectrum = background_spectrum + adaptive_threshold * new_unit_absorption_spectrum\n",
    "            high_target_spectrum = new_background_spectrum * new_unit_absorption_spectrum\n",
    "\n",
    "            radiancediff_with_bg[:,low_concentration_mask] = (\n",
    "                data_cube[:,low_concentration_mask] - background_spectrum[:,None]\n",
    "            )\n",
    "            radiancediff_with_bg[:,high_concentration_mask] = (\n",
    "                data_cube[:,high_concentration_mask] - new_background_spectrum[:,None]\n",
    "            )\n",
    "\n",
    "            d_covariance[:,high_concentration_mask] = data_cube[:,high_concentration_mask] - (\n",
    "                (concentration[high_concentration_mask]-adaptive_threshold)*high_target_spectrum[:,None] + new_background_spectrum[:,None]\n",
    "            )\n",
    "            d_covariance[:,low_concentration_mask] = data_cube[:,low_concentration_mask] - (\n",
    "                concentration[low_concentration_mask]*target_spectrum[:,None] + background_spectrum[:,None]\n",
    "            )\n",
    "        \n",
    "            covariance = np.zeros((bands, bands))\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "            covariance /= rows*cols\n",
    "            covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "                \n",
    "            concentration[high_concentration_mask] = (\n",
    "                (radiancediff_with_bg[:, high_concentration_mask].T @ covariance_inverse @ high_target_spectrum) / \n",
    "                (high_target_spectrum.T @ covariance_inverse @ high_target_spectrum)\n",
    "            )+ adaptive_threshold\n",
    "\n",
    "            concentration[low_concentration_mask] =(\n",
    "                (radiancediff_with_bg[:, low_concentration_mask].T @ covariance_inverse @ target_spectrum) / \n",
    "                (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            )\n",
    "\n",
    "        new_mean_concentration = np.nanmean(concentration)\n",
    "        new_std_concentration = np.nanstd(concentration)\n",
    "        new_adaptive_threshold = new_mean_concentration + new_std_concentration\n",
    "\n",
    "        if np.abs((new_adaptive_threshold - adaptive_threshold) / adaptive_threshold) > 0.5:\n",
    "            adaptive_threshold = new_adaptive_threshold\n",
    "            print(\"threshold is unstable, keep on iterating\")\n",
    "        else:\n",
    "            levelon = False\n",
    "            print(\"threshold is stable\")\n",
    "    return concentration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lognornal 匹配滤波算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the radiance into log space 整幅图像进行计算\n",
    "def lognormal_matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array):\n",
    "    # 获取 以 波段 行数 列数 为顺序的数据\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    # 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    log_background_spectrum = np.nanmean(np.log(data_cube), axis=(1,2))\n",
    "    background_spectrum = np.exp(log_background_spectrum)\n",
    "    \n",
    "    # 对当前目标光谱的每一行进行去均值操作，得到调整后的光谱，以此为基础计算协方差矩阵，并获得其逆矩阵\n",
    "    radiancediff_with_bg = np.log(data_cube) - log_background_spectrum[:, None,None]\n",
    "    d_covariance = np.log(data_cube)-background_spectrum[:,None,None]\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ unit_absorption_spectrum)\n",
    "            denominator = (unit_absorption_spectrum.T @ covariance_inverse @ unit_absorption_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "    return concentration\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchedfiltermethod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
