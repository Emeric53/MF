{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匹配滤波算法及其变体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要的库和依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"C:\\\\Users\\\\RS\\\\VSCode\\\\matchedfiltermethod\")\n",
    "import MyFunctions.AHSI_data as ad\n",
    "import MyFunctions.EMIT_data as ed\n",
    "from MyFunctions.needed_function import open_unit_absorption_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常规匹配滤波算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整幅影像计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# original matched filter algorithm 整幅图像进行计算\n",
    "def matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array, albedoadjust, iterate, sparsity):        \n",
    "    \"\"\"\n",
    "    Calculate the methane enhancement of the image data based on the original matched filter\n",
    "    and the unit absorption spectrum.\n",
    "    \n",
    "    :param data_array: numpy array of the image data\n",
    "    :param unit_absorption_spectrum: list of the unit absorption spectrum\n",
    "    \"\"\"\n",
    "    # 获取波段 行数 列数 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    \n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    background_spectrum = np.nanmean(data_cube, axis=(1,2))\n",
    "    target_spectrum = background_spectrum*unit_absorption_spectrum\n",
    "    radiancediff_with_bg =data_cube - background_spectrum[:, None,None]\n",
    "    \n",
    "    # 计算协方差矩阵，并获得其逆矩阵\n",
    "    d_covariance = radiancediff_with_bg\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "    \n",
    "    # 判断是否进行反照率校正，若是，则通过背景光谱和实际光谱计算反照率校正因子\n",
    "    albedo = np.ones((rows, cols))\n",
    "    if albedoadjust:\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                albedo[row, col] = (\n",
    "                        (data_cube[:,row,col].T @ background_spectrum) /\n",
    "                        (background_spectrum.T @ background_spectrum)\n",
    "                )\n",
    "    \n",
    "    # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum)\n",
    "            denominator = albedo[row,col]*(target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "    \n",
    "    # for row in range(rows):\n",
    "    #     for col in range(cols):\n",
    "    #         numerator = (radiancediff_with_bg[:,row,col].T @ target_spectrum)\n",
    "    #         denominator = albedo[row,col]*(target_spectrum.T @ target_spectrum)\n",
    "    #         concentration[row,col] = numerator/denominator\n",
    "    \n",
    "    # 判断是否进行迭代，若是，则进行如下迭代计算\n",
    "    if iterate:\n",
    "        # 初始化 l1filter 数组\n",
    "        l1filter = np.zeros((rows,cols))\n",
    "        for iter_num in range(5):\n",
    "            print(\"iteration: No.\", iter_num + 1)\n",
    "            # 判断是否进行 l1filter 校正，若是则给予前一步的浓度值计算 l1filter\n",
    "            if sparsity:\n",
    "                for row in rows:\n",
    "                    for col in cols:\n",
    "                        l1filter = 1 / (concentration[row,col] + np.finfo(np.float64).tiny)\n",
    "            \n",
    "            # 更新背景光谱和目标光谱,并计算进行观测光谱和背景光谱差值   \n",
    "            updated_array = data_cube - (albedo*concentration)[None,:,:]*target_spectrum[:,None,None]\n",
    "            background_spectrum = np.mean(updated_array, axis=(1,2))\n",
    "            target_spectrum = np.multiply(background_spectrum, unit_absorption_spectrum)\n",
    "            radiancediff_with_bg = data_cube - background_spectrum[:,None,None]\n",
    "            \n",
    "            # 基于新的目标谱和背景光谱 计算协方差矩阵\n",
    "            d_covariance = data_cube -(albedo*concentration)[None,:,:]*target_spectrum[:,None,None] - background_spectrum[:,None,None]\n",
    "            covariance = np.zeros((bands, bands))\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    covariance += np.outer(d_covariance[:,row,col], d_covariance[:,row,col])\n",
    "            covariance = covariance/(rows*cols)\n",
    "            covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "            # 基于最优化估计公式 计算新的甲烷浓度增强值\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum) - l1filter[row,col]\n",
    "                    denominator = albedo[row,col] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                    concentration[row,col] = np.maximum(numerator / denominator, 0.0)\n",
    "                  \n",
    "            # for row in range(rows):\n",
    "            #     for col in range(cols):\n",
    "            #         numerator = (radiancediff_with_bg[:,row,col].T @ target_spectrum) - l1filter[row,col]\n",
    "            #         denominator = albedo[row,col] * (target_spectrum.T @ target_spectrum)\n",
    "            #         concentration[row,col] = np.maximum(numerator / denominator, 0.0)\n",
    "    return concentration\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column-wise 进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orginal matched filter algorithm 逐列计算\n",
    "def columnwise_matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array, iterate=False,\n",
    "                   albedoadjust=False, sparsity=False):\n",
    "    \"\"\"\n",
    "    Calculate the methane enhancement of the image data based on the original matched filter\n",
    "    and the unit absorption spectrum.\n",
    "\n",
    "    :param data_cube: numpy array of the image data\n",
    "    :param unit_absorption_spectrum: list of the unit absorption spectrum\n",
    "    :param iterate: flag to decide whether to iterate the matched filter\n",
    "    :param albedoadjust: flag to decide whether to do the albedo correction\n",
    "    :param sparsity: flag to decide whether to add the l1-filter correction\n",
    "    :return: numpy array of methane enhancement result\n",
    "    \"\"\"\n",
    "    # 获取波段 行数 列数 ,并初始化 concentration 数组\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    \n",
    "    # 遍历不同列数，目的是为了消除 不同传感器之间带来的误差\n",
    "    for col_index in range(cols):\n",
    "        # 获取当前列的数据 获取当前列的非空行的 索引 以及 数目\n",
    "        current_column = data_cube[:, :, col_index]\n",
    "        valid_rows = ~np.isnan(current_column[0, :])\n",
    "        count_not_nan = np.count_nonzero(valid_rows)\n",
    "        \n",
    "        # 对于全为空的列，直接将浓度值设为 nan\n",
    "        if count_not_nan == 0:\n",
    "            concentration[:, col_index] = np.nan\n",
    "            continue\n",
    "\n",
    "        # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱,并计算观测光谱和背景光谱的差值\n",
    "        background_spectrum = np.nanmean(current_column, axis=1)\n",
    "        target_spectrum = background_spectrum*unit_absorption_spectrum\n",
    "        radiancediff_with_bg = current_column[:, valid_rows] - background_spectrum[:, None]\n",
    "        \n",
    "        # 计算协方差矩阵，并获得其逆矩阵\n",
    "        d_covariance = radiancediff_with_bg\n",
    "        covariance = np.zeros((bands, bands))\n",
    "        for i in range(count_not_nan):\n",
    "            covariance += np.outer(d_covariance[:, i], d_covariance[:, i])\n",
    "        covariance = covariance/count_not_nan\n",
    "        covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "        # 判断是否进行反照率校正，若是，则通过背景光谱和实际光谱计算反照率校正因子\n",
    "        albedo = np.ones((rows, cols))\n",
    "        if albedoadjust:\n",
    "            albedo[valid_rows, col_index] = (\n",
    "                    (current_column[:, valid_rows].T @ background_spectrum) /\n",
    "                    (background_spectrum.T @ background_spectrum)\n",
    "            )\n",
    "\n",
    "        # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "        numerator = (radiancediff_with_bg.T @ covariance_inverse @ target_spectrum)\n",
    "        denominator = albedo[valid_rows, col_index] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "        concentration[valid_rows, col_index] = numerator/denominator\n",
    "        \n",
    "        # 判断是否进行迭代，若是，则进行如下迭代计算\n",
    "        if iterate:\n",
    "            # 初始化 l1filter 数组\n",
    "            l1filter = np.zeros((rows, cols))\n",
    "            epsilon = np.finfo(np.float64).tiny\n",
    "            # 迭代计算\n",
    "            for iter_num in range(5):\n",
    "                print(\"iteration: No.\", iter_num + 1)\n",
    "                # 判断是否进行 l1filter 校正，若是则给予前一步的浓度值计算 l1filter\n",
    "                if sparsity:\n",
    "                    l1filter[valid_rows, col_index] = 1 / (concentration[valid_rows, col_index] + epsilon)\n",
    "        \n",
    "                # 更新背景光谱和目标光谱，计算进行观测光谱和背景光谱差值\n",
    "                column_replacement = current_column[:, valid_rows] - (albedo[valid_rows, col_index] *concentration[valid_rows, col_index])[None,:]*target_spectrum[:,None]\n",
    "                background_spectrum = np.nanmean(column_replacement, axis=1)\n",
    "                target_spectrum = np.multiply(background_spectrum, unit_absorption_spectrum)\n",
    "                radiancediff_with_bg = current_column[:, valid_rows] - background_spectrum\n",
    "                \n",
    "                # 是否要更新反照率校正因子？\n",
    "                # if albedoadjust:\n",
    "                #     albedo[valid_rows, col_index] = (\n",
    "                #             (current_column[:, valid_rows].T @ background_spectrum) /\n",
    "                #             (background_spectrum.T @ background_spectrum)\n",
    "                #     )\n",
    "                \n",
    "                # 基于新的目标谱 和 背景光谱 计算协方差矩阵\n",
    "                d_covariance = current_column[:, valid_rows] -(albedo[valid_rows, col_index] *concentration[valid_rows, col_index])[None,:]*target_spectrum[:,None] - background_spectrum[:,None]\n",
    "                covariance = np.zeros((bands, bands))\n",
    "                for i in range(valid_rows.shape[0]):\n",
    "                    covariance += np.outer(d_covariance[:, i], d_covariance[:, i])\n",
    "                covariance = covariance/count_not_nan\n",
    "                covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "                # 计算新的甲烷浓度增强值\n",
    "                numerator = (radiancediff_with_bg.T @ covariance_inverse @ target_spectrum) - l1filter[valid_rows, col_index]\n",
    "                denominator = albedo[valid_rows, col_index] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                concentration[valid_rows, col_index] = np.maximum(numerator / denominator, 0.0)\n",
    "                \n",
    "    # 返回甲烷浓度增强和反照率校正\n",
    "    return concentration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层匹配滤波算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整幅图像进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# modified matched filter algorithm 整幅图像进行计算\n",
    "def modified_matched_filter_copy(data_cube: np.array, unit_absorption_spectrum: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Calculate the methane enhancement of the image data based on the original matched filter\n",
    "    and the unit absorption spectrum.\n",
    "\n",
    "    :param data_cube: numpy array of the image data\n",
    "    :param unit_absorption_spectrum: list of the unit absorption spectrum\n",
    "    :param is_iterate: flag to decide whether to iterate the matched filter\n",
    "    :param is_albedo: flag to decide whether to do the albedo correction\n",
    "    :param is_filter: flag to decide whether to add the l1-filter correction\n",
    "    :return: numpy array of methane enhancement result\n",
    "    \"\"\"\n",
    "    # 获取 以 波段 行数 列数 为顺序的数据\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    # 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    background_spectrum = np.nanmean(data_cube, axis=(1,2))\n",
    "    target_spectrum = background_spectrum*unit_absorption_spectrum[0]\n",
    "    radiancediff_with_bg = data_cube - background_spectrum[:, None,None]\n",
    "\n",
    "    d_covariance = data_cube - background_spectrum[:, None,None]\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum)\n",
    "            denominator = (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "\n",
    "    original_concentration = concentration.copy()\n",
    "    levelon = True\n",
    "    while levelon:\n",
    "        adaptive_threshold = 4000\n",
    "        i = 1\n",
    "        # _, new_unit_absorption_spectrum = lookup_uas_interpolated(adaptive_threshold)\n",
    "        new_unit_absorption_spectrum = unit_absorption_spectrum[i]\n",
    "        high_concentration_mask = concentration > adaptive_threshold\n",
    "        low_concentration_mask = concentration <= adaptive_threshold\n",
    "        if np.sum(high_concentration_mask) > 0:\n",
    "            # 注意：target_spectrum 的更新应该基于更准确的估计值\n",
    "            background_spectrum = np.nanmean(data_cube - concentration * target_spectrum[:, None, None], axis=(1, 2))\n",
    "            target_spectrum = background_spectrum * unit_absorption_spectrum\n",
    "            new_background_spectrum = background_spectrum + adaptive_threshold * new_unit_absorption_spectrum\n",
    "            high_target_spectrum = new_background_spectrum * new_unit_absorption_spectrum\n",
    "\n",
    "            radiancediff_with_bg[:,low_concentration_mask] = (\n",
    "                data_cube[:,low_concentration_mask] - background_spectrum[:,None]\n",
    "            )\n",
    "            radiancediff_with_bg[:,high_concentration_mask] = (\n",
    "                data_cube[:,high_concentration_mask] - new_background_spectrum[:,None]\n",
    "            )\n",
    "\n",
    "            d_covariance[:,high_concentration_mask] = data_cube[:,high_concentration_mask] - (\n",
    "                (concentration[high_concentration_mask]-adaptive_threshold)*high_target_spectrum[:,None] + new_background_spectrum[:,None]\n",
    "            )\n",
    "            d_covariance[:,low_concentration_mask] = data_cube[:,low_concentration_mask] - (\n",
    "                concentration[low_concentration_mask]*target_spectrum[:,None] + background_spectrum[:,None]\n",
    "            )\n",
    "        \n",
    "            covariance = np.zeros((bands, bands))\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "            covariance /= rows*cols\n",
    "            covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "                \n",
    "            concentration[high_concentration_mask] = (\n",
    "                (radiancediff_with_bg[:, high_concentration_mask].T @ covariance_inverse @ high_target_spectrum) / \n",
    "                (high_target_spectrum.T @ covariance_inverse @ high_target_spectrum)\n",
    "            )+ adaptive_threshold\n",
    "\n",
    "            concentration[low_concentration_mask] =(\n",
    "                (radiancediff_with_bg[:, low_concentration_mask].T @ covariance_inverse @ target_spectrum) / \n",
    "                (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            )\n",
    "\n",
    "        new_mean_concentration = np.nanmean(concentration)\n",
    "        new_std_concentration = np.nanstd(concentration)\n",
    "        new_adaptive_threshold = new_mean_concentration + new_std_concentration\n",
    "\n",
    "        if np.abs((new_adaptive_threshold - adaptive_threshold) / adaptive_threshold) > 0.5:\n",
    "            adaptive_threshold = new_adaptive_threshold\n",
    "            print(\"threshold is unstable, keep on iterating\")\n",
    "        else:\n",
    "            levelon = False\n",
    "            print(\"threshold is stable\")\n",
    "    return concentration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column-wise 进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# modified matched filter algorithm 逐列计算\n",
    "def columnwise_modified_matched_filter(data_array: np.array, stacked_unit_absorption_spectrum: np.array, is_iterate=False,\n",
    "                   is_albedo=False, is_filter=False, is_columnwise=False) -> np.array:\n",
    "    \"\"\"\n",
    "    Calculate the methane enhancement of the image data based on the original matched filter\n",
    "    and the unit absorption spectrum.\n",
    "\n",
    "    :param data_array: numpy array of the image data\n",
    "    :param unit_absorption_spectrum: list of the unit absorption spectrum\n",
    "    :param is_iterate: flag to decide whether to iterate the matched filter\n",
    "    :param is_albedo: flag to decide whether to do the albedo correction\n",
    "    :param is_filter: flag to decide whether to add the l1-filter correction\n",
    "    :return: numpy array of methane enhancement result\n",
    "    \"\"\"\n",
    "    # 获取 以 波段 行数 列数 为顺序的数据\n",
    "    bands, rows, cols = data_array.shape\n",
    "    # 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    # 遍历不同列数，目的是为了消除 不同传感器之间带来的误差\n",
    "    if is_columnwise:\n",
    "        for col_index in range(cols):\n",
    "            # 获取当前列的数据\n",
    "            current_column = data_array[:, :, col_index]\n",
    "            # 获取当前列的非空行的 索引 以及 数目\n",
    "            valid_rows = ~np.isnan(current_column[0, :])\n",
    "            count_not_nan = np.count_nonzero(valid_rows)\n",
    "            # 对于全为空的列，直接将浓度值设为 nan\n",
    "            if count_not_nan == 0:\n",
    "                concentration[:, col_index] = np.nan\n",
    "                continue\n",
    "\n",
    "            # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "            background_spectrum = np.nanmean(current_column, axis=1)\n",
    "            target_spectrum = background_spectrum*stacked_unit_absorption_spectrum[0,:]\n",
    "\n",
    "            # 对当前目标光谱的每一行进行去均值操作，得到调整后的光谱，以此为基础计算协方差矩阵，并获得其逆矩阵\n",
    "            radiancediff_with_bg = current_column[:, valid_rows] - background_spectrum[:, None]\n",
    "            covariance = np.zeros((bands, bands))\n",
    "            for i in range(count_not_nan):\n",
    "                covariance += np.outer(radiancediff_with_bg[:, i], radiancediff_with_bg[:, i])\n",
    "            covariance = covariance/count_not_nan\n",
    "            covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "            # 判断是否进行反照率校正，若是，则通过背景光谱和实际光谱计算反照率校正因子\n",
    "            albedo = np.ones((rows, cols))\n",
    "            if is_albedo:\n",
    "                albedo[valid_rows, col_index] = (\n",
    "                        (current_column[:, valid_rows].T @ background_spectrum) /\n",
    "                        (background_spectrum.T @ background_spectrum)\n",
    "                )\n",
    "\n",
    "            # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "            up = (radiancediff_with_bg.T @ covariance_inverse @ target_spectrum)\n",
    "            down = albedo[valid_rows, col_index] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            concentration[valid_rows, col_index] = up / down\n",
    "            \n",
    "            levelon = True\n",
    "            # 计算浓度增强值的均值和标准差\n",
    "            mean_concentration = np.nanmean(concentration[valid_rows, col_index])  # 忽略 NaN 值\n",
    "            std_concentration = np.nanstd(concentration[valid_rows, col_index])    # 忽略 NaN 值\n",
    "            # 使用均值加一个标准差作为自适应阈值\n",
    "            adaptive_threshold = mean_concentration + std_concentration\n",
    "            while levelon:\n",
    "                high_concentration_mask = concentration[valid_rows, col_index] > adaptive_threshold\n",
    "                # 获取这个阈值的单位吸收谱，可以通过插值查找表获得\n",
    "                # 使用新的单位吸收谱重新计算目标光谱\n",
    "                background_spectrum = np.nanmean(current_column[:,valid_rows] + albedo[valid_rows,col_index]*concentration[valid_rows,col_index]*target_spectrum[:, np.newaxis], axis=1)\n",
    "                background_spectrum = background_spectrum + adaptive_threshold*stacked_unit_absorption_spectrum[1,:]\n",
    "                target_spectrum = np.multiply(background_spectrum, stacked_unit_absorption_spectrum[1,:])\n",
    "                radiancediff_with_bg = current_column[:, valid_rows] - background_spectrum[:, None] - albedo[valid_rows,col_index]*(concentration[valid_rows,col_index]-adaptive_threshold)*target_spectrum[:, np.newaxis] \n",
    "                covariance = np.zeros((bands, bands))\n",
    "                for i in range(valid_rows.shape[0]):\n",
    "                    covariance += np.outer(radiancediff_with_bg[:, i], radiancediff_with_bg[:, i])\n",
    "                covariance = covariance/count_not_nan\n",
    "                covariance_inverse = np.linalg.inv(covariance)\n",
    "                # 基于新的目标光谱重新计算高浓度像素的甲烷浓度增强值\n",
    "                up = (radiancediff_with_bg[:, high_concentration_mask].T @ covariance_inverse @ target_spectrum)\n",
    "                down = albedo[valid_rows, col_index][high_concentration_mask] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                # 直接更新原数组\n",
    "                valid_indices = np.where(valid_rows)[0]\n",
    "                high_concentration_indices = valid_indices[high_concentration_mask]\n",
    "                concentration[high_concentration_indices, col_index] = up / down + adaptive_threshold\n",
    "                # 计算浓度增强值的均值和标准差\n",
    "                mean_concentration = np.nanmean(concentration[valid_rows, col_index])  # 忽略 NaN 值\n",
    "                std_concentration = np.nanstd(concentration[valid_rows, col_index])    # 忽略 NaN 值\n",
    "                # 使用均值加一个标准差作为自适应阈值\n",
    "                new_adaptive_threshold = mean_concentration + std_concentration\n",
    "                if np.abs((new_adaptive_threshold-adaptive_threshold)/adaptive_threshold) < 0.1:\n",
    "                    adaptive_threshold = new_adaptive_threshold\n",
    "                else:\n",
    "                    levelon = False\n",
    "\n",
    "            # 判断是否进行迭代，若是，则进行如下迭代计算\n",
    "            if is_iterate:\n",
    "                l1filter = np.zeros((rows, cols))\n",
    "                epsilon = np.finfo(np.float32).tiny\n",
    "                for iter_num in range(5):\n",
    "                    if is_filter:\n",
    "                        l1filter[valid_rows, col_index] = 1 / (concentration[valid_rows, col_index] + epsilon)\n",
    "                    else:\n",
    "                        l1filter[valid_rows, col_index] = 0\n",
    "                    \n",
    "                    # 更新背景光谱和目标光谱\n",
    "                    column_replacement = current_column[:, valid_rows] - (albedo[valid_rows, col_index] *concentration[valid_rows, col_index])[None,:]*target_spectrum[:,None]\n",
    "                    # 计算更新后的 背景光谱 和 目标谱\n",
    "                    background_spectrum = np.mean(column_replacement, axis=1)\n",
    "                    target_spectrum = np.multiply(background_spectrum, stacked_unit_absorption_spectrum[0,:])\n",
    "                    # 基于新的目标谱 和 背景光谱 计算协方差矩阵\n",
    "                    radiancediff_with_bg = current_column[:, valid_rows] -(albedo[valid_rows, col_index] *concentration[valid_rows, col_index])[None,:]*target_spectrum[:,None] - background_spectrum[:,None]\n",
    "                    covariance = np.zeros((bands, bands))\n",
    "                    for i in range(valid_rows.shape[0]):\n",
    "                        covariance += np.outer(radiancediff_with_bg[:, i], radiancediff_with_bg[:, i])\n",
    "                    covariance = covariance/count_not_nan\n",
    "                    covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "                    # 计算新的甲烷浓度增强值\n",
    "                    up = (radiancediff_with_bg.T @ covariance_inverse @ target_spectrum) - l1filter[valid_rows, col_index]\n",
    "                    down = albedo[valid_rows, col_index] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                    concentration[valid_rows, col_index] = np.maximum(up / down, 0.0)\n",
    "                    high_concentration_mask = concentration[valid_rows, col_index] > 5000\n",
    "                    \n",
    "                    if np.any(high_concentration_mask):\n",
    "                        # 使用新的单位吸收谱重新计算目标光谱\n",
    "                        con = concentration[valid_rows, col_index].copy()\n",
    "                        background_spectrum = np.nanmean(current_column[:,valid_rows] - albedo[valid_rows,col_index]*con*target_spectrum[:, np.newaxis], axis=1)\n",
    "                        target_spectrum = np.multiply(background_spectrum, stacked_unit_absorption_spectrum)\n",
    "                        radiancediff_with_bg = current_column[:, valid_rows] -albedo[valid_rows,col_index]*con*target_spectrum[:, np.newaxis] - background_spectrum[:, None]\n",
    "                        covariance = np.zeros((bands, bands))\n",
    "                        for i in range(valid_rows.shape[0]):\n",
    "                            covariance += np.outer(radiancediff_with_bg[:, i], radiancediff_with_bg[:, i])\n",
    "                        covariance = covariance/count_not_nan\n",
    "                        covariance_inverse = np.linalg.inv(covariance)\n",
    "                        # 基于新的目标光谱重新计算高浓度像素的甲烷浓度增强值\n",
    "                        up = (radiancediff_with_bg[:, high_concentration_mask].T @ covariance_inverse @ target_spectrum)\n",
    "                        down = albedo[valid_rows, col_index][high_concentration_mask] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                        # 直接更新原数组\n",
    "                        valid_indices = np.where(valid_rows)[0]\n",
    "                        high_concentration_indices = valid_indices[high_concentration_mask]\n",
    "                        concentration[high_concentration_indices, col_index] = up / down + 2500\n",
    "\n",
    "    if not is_columnwise:\n",
    "        count_not_nan = np.count_nonzero(~np.isnan(data_array[0, :, :]))\n",
    "        background_spectrum = np.nanmean(data_array, axis=(1,2))\n",
    "        target_spectrum = np.multiply(background_spectrum, stacked_unit_absorption_spectrum[0,:])   \n",
    "        radiancediff_with_bg = data_array - background_spectrum[:, None, None]\n",
    "        covariance = np.zeros((bands, bands))\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                covariance = covariance + np.outer(radiancediff_with_bg[:, i, j], radiancediff_with_bg[:, i, j])\n",
    "        covariance = covariance / count_not_nan\n",
    "        covariance_inverse = np.linalg.inv(covariance)\n",
    "        albedo = np.ones((rows, cols))\n",
    "        for row_index in range(rows):\n",
    "            for col_index in range(cols):\n",
    "                if is_albedo:\n",
    "                    albedo[row_index, col_index] = (\n",
    "                        (data_array[:, row_index, col_index].T @ background_spectrum) /\n",
    "                        (background_spectrum.T @ background_spectrum)\n",
    "                    )\n",
    "                up = (radiancediff_with_bg[:,row_index,col_index].T @ covariance_inverse @ target_spectrum)\n",
    "                down = albedo[row_index, col_index] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                concentration[row_index, col_index] = up / down\n",
    "        \n",
    "        if is_iterate:\n",
    "            l1filter = np.zeros((rows, cols))\n",
    "            epsilon = np.finfo(np.float32).tiny\n",
    "            iter_data = data_array.copy()\n",
    "            \n",
    "            for iter_num in range(5):\n",
    "                if is_filter:\n",
    "                    l1filter = 1 / (concentration + epsilon)\n",
    "                iter_data = data_array - (\n",
    "                    target_spectrum[:, None, None] * albedo[None, :, :] * concentration[None, :, :]\n",
    "                )\n",
    "                background_spectrum = np.nanmean(iter_data, axis=(1,2))\n",
    "                target_spectrum = np.multiply(background_spectrum, stacked_unit_absorption_spectrum[0,:])\n",
    "                radiancediff_with_bg = data_array - background_spectrum[:, None, None]\n",
    "                covariance = np.zeros((bands, bands))\n",
    "                for i in range(rows):\n",
    "                    for j in range(cols):\n",
    "                        covariance += np.outer(radiancediff_with_bg[:, i, j], radiancediff_with_bg[:, i, j])\n",
    "                covariance = covariance / count_not_nan\n",
    "                covariance_inverse = np.linalg.inv(covariance)\n",
    "                \n",
    "                for row_index in range(rows):\n",
    "                    for col_index in range(cols):\n",
    "                        up = (radiancediff_with_bg[:, row_index, col_index].T @ covariance_inverse @ target_spectrum)\n",
    "                        down = albedo[row_index, col_index] * (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "                        concentration[row_index, col_index] = np.maximum(up / down, 0)\n",
    "\n",
    "    # 返回 甲烷浓度增强的结果\n",
    "    return concentration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lognornal 匹配滤波算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整幅影像进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the radiance into log space 整幅图像进行计算\n",
    "def lognormal_matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array):\n",
    "    # 获取 以 波段 行数 列数 为顺序的数据\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    # 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    log_background_spectrum = np.nanmean(np.log(data_cube), axis=(1,2))\n",
    "    background_spectrum = np.exp(log_background_spectrum)\n",
    "    \n",
    "    # 对当前目标光谱的每一行进行去均值操作，得到调整后的光谱，以此为基础计算协方差矩阵，并获得其逆矩阵\n",
    "    radiancediff_with_bg = np.log(data_cube) - log_background_spectrum[:, None,None]\n",
    "    d_covariance = np.log(data_cube)-background_spectrum[:,None,None]\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(d_covariance[:, row, col], d_covariance[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ unit_absorption_spectrum)\n",
    "            denominator = (unit_absorption_spectrum.T @ covariance_inverse @ unit_absorption_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "    return concentration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column-wise 进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the radiance into log space 逐列计算\n",
    "def columnwise_lognormal_matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array):\n",
    "    # 获取 以 波段 行数 列数 为顺序的数据\n",
    "    bands, rows, cols = data_cube.shape\n",
    "    # 初始化 concentration 数组，大小与卫星数据尺寸一直\n",
    "    concentration = np.zeros((rows, cols))\n",
    "    # 对于非空列，取均值作为背景光谱，再乘以单位吸收光谱，得到目标光谱\n",
    "    background_spectrum = np.nanmean(data_cube, axis=(1,2))\n",
    "    target_spectrum = background_spectrum*unit_absorption_spectrum\n",
    "\n",
    "    # 对当前目标光谱的每一行进行去均值操作，得到调整后的光谱，以此为基础计算协方差矩阵，并获得其逆矩阵\n",
    "    radiancediff_with_bg = data_cube - background_spectrum[:, None,None]\n",
    "    covariance = np.zeros((bands, bands))\n",
    "    for row in range(rows): \n",
    "        for col in range(cols):\n",
    "            covariance += np.outer(radiancediff_with_bg[:, row, col], radiancediff_with_bg[:, row, col])\n",
    "    covariance = covariance/(rows*cols)\n",
    "    covariance_inverse = np.linalg.inv(covariance)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # 基于最优化公式计算每个像素的甲烷浓度增强值\n",
    "            numerator = (radiancediff_with_bg[:,row,col].T @ covariance_inverse @ target_spectrum)\n",
    "            denominator = (target_spectrum.T @ covariance_inverse @ target_spectrum)\n",
    "            concentration[row,col] = numerator/denominator\n",
    "    return concentration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Kalman filter 匹配滤波算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整幅影像进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kalman_filterr_matched_filter(data_cube: np.array, unit_absorption_spectrum: np.array, albedoadjust, iterate, sparsity):\n",
    "    \n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchedfiltermethod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
